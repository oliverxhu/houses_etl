{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "import datetime\n",
    "import requests\n",
    "import json\n",
    "import ETLTools\n",
    "\n",
    "\n",
    "class LocationMetadata(ETLTools.ETLTools):\n",
    "    def __init__(self, **kwargs):\n",
    "        # connection object for staging\n",
    "        if kwargs.get('connect_staging', None):\n",
    "            self.con_staging = ETLTools.DatabaseConnection(\n",
    "                kwargs['st_user'], kwargs['st_passwd'], kwargs['st_host'], kwargs['st_db'], kwargs['st_schema'])\n",
    "        # connection object for website\n",
    "        if kwargs.get('connect_website', None):\n",
    "            self.con_website = ETLTools.DatabaseConnection(\n",
    "                kwargs['ws_user'], kwargs['ws_passwd'], kwargs['ws_host'], kwargs['ws_db'], kwargs['ws_schema'])\n",
    "        # run location api\n",
    "        if location_api:\n",
    "            data = requests.get(location_api)\n",
    "            area = json.loads(data.text)\n",
    "            self.districts = json_normalize(area, 'Districts', ['LocalityId', 'Name'], meta_prefix='LocalityMetadata')\n",
    "            self.region_df = self.run_region()\n",
    "            self.district_df = self.run_district()\n",
    "            self.suburb_df = self.run_suburb()\n",
    "            self.location_df = None\n",
    "            self.adjacent_suburbs_df = None\n",
    "            self._region_updated = False\n",
    "            self._district_updated = False\n",
    "            self._suburb_updated = False\n",
    "            self._location_updated = False\n",
    "            self._adjacent_suburbs_updated = False\n",
    "\n",
    "    def location(self):\n",
    "        \"\"\"\n",
    "        :return: normalised dataframe of all location trademe-ids and their names\n",
    "        \"\"\"\n",
    "        suburbs_list = pd.DataFrame(columns=['SuburbId', 'Name', 'DistrictId'])\n",
    "        for index, row in self.districts.iterrows():\n",
    "            suburbs = json_normalize(json.loads(json.dumps(row['Suburbs'])), meta=['SuburbId', 'Name'])\n",
    "            suburbs = suburbs.assign(DistrictId=row['DistrictId'])\n",
    "            suburbs = suburbs.drop('AdjacentSuburbs', axis=1)\n",
    "            suburbs_list = pd.concat([suburbs_list, suburbs])\n",
    "\n",
    "        locations = pd.merge(left=self.districts.drop('Suburbs', axis=1), right=suburbs_list,\n",
    "                             how='inner', left_on='DistrictId', right_on='DistrictId',\n",
    "                             suffixes=('_district', '_suburb'))\n",
    "        locations.columns = ['id_district_tm', 'district_name', 'id_region_tm',\n",
    "                             'region_name', 'suburb_name', 'id_suburb_tm']\n",
    "        locations['id_suburb_tm'] = locations['id_suburb_tm'].apply(int)  # suburbs is decimal for some reason\n",
    "        return self.trim_dataframe(locations, ['district_name', 'region_name', 'suburb_name'])\n",
    "\n",
    "    def run_region(self):\n",
    "        \"\"\"Populates self.region_df for `region`. Runs in the constructor.\"\"\"\n",
    "        region_df = self.location()[['id_region_tm', 'region_name']]\n",
    "        region_df['last_updated'] = datetime.datetime.now()\n",
    "        region_df = region_df.rename(columns={'region_name': 'name'})\n",
    "        return region_df.drop_duplicates(subset=['id_region_tm', 'name'])\n",
    "\n",
    "    def run_district(self):\n",
    "        \"\"\"Populates self.district_df for `district`. Runs in the constructor.\"\"\"\n",
    "        district_df = self.location()[['id_district_tm', 'district_name']]\n",
    "        district_df['last_updated'] = datetime.datetime.now()\n",
    "        district_df = district_df.rename(columns={'district_name': 'name'})\n",
    "        return district_df.drop_duplicates(subset=['id_district_tm', 'name'])\n",
    "\n",
    "    def run_suburb(self):\n",
    "        \"\"\"Populates self.suburb_df for `suburb`. Runs in the constructor.\"\"\"\n",
    "        suburb_df = self.location()[['id_suburb_tm', 'suburb_name']]\n",
    "        suburb_df['last_updated'] = datetime.datetime.now()\n",
    "        suburb_df = suburb_df.rename(columns={'suburb_name': 'name'})\n",
    "        return suburb_df.drop_duplicates(subset=['id_suburb_tm', 'name'])\n",
    "\n",
    "    def run_location(self):\n",
    "        \"\"\"Populates self.location_df for database table `location`\"\"\"\n",
    "        if not (self._region_updated and self._district_updated and self._suburb_updated):\n",
    "            print(\"Warning: Running location table without having updated district, region and suburb\"\n",
    "                  \" in this class instance\")\n",
    "        location_df = self.location()[['id_district_tm', 'id_region_tm', 'id_suburb_tm']]\n",
    "        for tbltype in ('region', 'district', 'suburb'):\n",
    "            location_df = self.con_website.table_lookup(df=location_df, df_lookup_column_list=['id_%s_tm' % tbltype],\n",
    "                                                        table='analytics_%s' % tbltype,\n",
    "                                                        table_lookup_column_list=['id_%s_tm' % tbltype],\n",
    "                                                        table_return_column_list=['id_%s' % tbltype],\n",
    "                                                        return_suffix='_tblid', indicator=False)\n",
    "        location_df = location_df.drop(['id_district_tm', 'id_region_tm', 'id_suburb_tm'], axis=1)\n",
    "        location_df['last_updated'] = datetime.datetime.now()\n",
    "        self.location_df = location_df.rename(columns={\n",
    "            'id_region_tblid': 'id_region',\n",
    "            'id_district_tblid': 'id_district',\n",
    "            'id_suburb_tblid': 'id_suburb'\n",
    "        })\n",
    "\n",
    "    def run_adjacent_suburbs(self):\n",
    "        \"\"\"Populates self.adjacent_suburbs_df for database table `adjacent_suburbs`\"\"\"\n",
    "        suburbs_list = pd.DataFrame(columns=['AdjacentSuburbId', 'SuburbId'])\n",
    "        for index, row in self.districts.iterrows():\n",
    "            suburbs = json_normalize(json.loads(json.dumps(row['Suburbs'])), 'AdjacentSuburbs', ['SuburbId', 'Name'])\n",
    "            suburbs.columns = ['AdjacentSuburbId', 'SuburbId', 'Name']\n",
    "            suburbs = suburbs.drop('Name', axis=1)\n",
    "            suburbs_list = pd.concat([suburbs_list, suburbs])\n",
    "\n",
    "        # get rid of rows where suburb == adjacent suburb (the api lists the own suburb as an adjacent suburb)\n",
    "        suburbs_list['check'] = suburbs_list['AdjacentSuburbId'] - suburbs_list['SuburbId']\n",
    "        suburbs_list = suburbs_list[suburbs_list['check'] != 0]\n",
    "        suburbs_list = suburbs_list.drop('check', axis=1)\n",
    "        suburbs_list.columns = ['id_adjacent_suburb_tm', 'id_suburb_tm']\n",
    "        suburbs_list = self.con_website.table_lookup(df=suburbs_list, df_lookup_column_list=['id_suburb_tm'],\n",
    "                                                     table='analytics_suburb',\n",
    "                                                     table_lookup_column_list=['id_suburb_tm'],\n",
    "                                                     table_return_column_list=['id_suburb'], return_suffix='_tblid',\n",
    "                                                     indicator=False)\n",
    "        suburbs_list = self.con_website.table_lookup(df=suburbs_list, df_lookup_column_list=['id_adjacent_suburb_tm'],\n",
    "                                                     table='analytics_suburb',\n",
    "                                                     table_lookup_column_list=['id_suburb_tm'],\n",
    "                                                     table_return_column_list=['id_suburb'], return_suffix='_adjtblid',\n",
    "                                                     indicator=False)\n",
    "        suburbs_list = suburbs_list.drop(['id_adjacent_suburb_tm', 'id_suburb_tm', 'id_suburb_tm_adjtblid'], axis=1)\n",
    "        suburbs_list['last_updated'] = datetime.datetime.now()\n",
    "        suburbs_list = suburbs_list.dropna(axis=0)\n",
    "        self.adjacent_suburbs_df = suburbs_list.rename(columns={\n",
    "            'id_suburb_tblid': 'id_suburb',\n",
    "            'id_suburb_adjtblid': 'id_suburb_adjacent'\n",
    "        })\n",
    "\n",
    "    def update_region_table(self):\n",
    "        \"\"\"Update region metadata table\"\"\"\n",
    "        self.con_website.update_scd_type_one(self.region_df, dimension_table='analytics_region', key='id_region',\n",
    "                                             attributeslist=['id_region_tm', 'name', 'last_updated'],\n",
    "                                             lookupatts=['id_region_tm'], type1atts=['name', 'last_updated'])\n",
    "        self._region_updated = True\n",
    "\n",
    "    def update_district_table(self):\n",
    "        \"\"\"Update district metadata table\"\"\"\n",
    "        self.con_website.update_scd_type_one(self.district_df, dimension_table='analytics_district', key='id_district',\n",
    "                                             attributeslist=['id_district_tm', 'name', 'last_updated'],\n",
    "                                             lookupatts=['id_district_tm'], type1atts=['name', 'last_updated'])\n",
    "        self._district_updated = True\n",
    "\n",
    "    def update_suburb_table(self):\n",
    "        \"\"\"Update suburb metadata table\"\"\"\n",
    "        self.con_website.update_scd_type_one(self.suburb_df, dimension_table='analytics_suburb', key='id_suburb',\n",
    "                                             attributeslist=['id_suburb_tm', 'name', 'last_updated'],\n",
    "                                             lookupatts=['id_suburb_tm'], type1atts=['name', 'last_updated'])\n",
    "        self._suburb_updated = True\n",
    "\n",
    "    def write_location_table(self):\n",
    "        \"\"\"Only for first time writing, or after truncating\"\"\"\n",
    "        self.run_location()\n",
    "        self.con_website.append_df_to_table(df=self.location_df, table='analytics_location')\n",
    "\n",
    "    def update_location_table(self):\n",
    "        \"\"\"Update location metadata table. This requires all 3 location tables to be updated\"\"\"\n",
    "        self.run_location()\n",
    "        self.con_website.add_new_records(df=self.location_df,\n",
    "                                         df_lookup_column_list=['id_region', 'id_district', 'id_suburb'],\n",
    "                                         table='analytics_location',\n",
    "                                         table_lookup_column_list=['id_region', 'id_district', 'id_suburb'])\n",
    "        self._location_updated = True\n",
    "\n",
    "    def update_adjacent_suburbs_table(self):\n",
    "        \"\"\"Update adjacent suburbs metadata table. This requires suburb metadata table to be updated\"\"\"\n",
    "        self.run_adjacent_suburbs()\n",
    "        self.con_website.add_new_records(df=self.adjacent_suburbs_df,\n",
    "                                         df_lookup_column_list=['id_suburb', 'id_suburb_adjacent'],\n",
    "                                         table='analytics_adjacent_suburbs',\n",
    "                                         table_lookup_column_list=['id_suburb', 'id_suburb_adjacent'])\n",
    "        self._adjacent_suburbs_updated = True\n",
    "\n",
    "with open('API.json') as file:\n",
    "    location_api = json.load(file)\n",
    "    location_api = location_api['location_api']\n",
    "\n",
    "with open('website_connection.json') as file:\n",
    "    web_con = json.load(file)\n",
    "\n",
    "location_md = LocationMetadata(location_api=location_api,\n",
    "                               connect_website=True, ws_user=web_con['ws_user'], ws_passwd=web_con['ws_passwd'],\n",
    "                               ws_host=web_con['ws_host'], ws_db=web_con['ws_db'], ws_schema=web_con['ws_schema'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "suburbs_list = pd.DataFrame(columns=['AdjacentSuburbId', 'SuburbId'])\n",
    "for index, row in location_md.districts.iterrows():\n",
    "    suburbs = json_normalize(json.loads(json.dumps(row['Suburbs'])), 'AdjacentSuburbs', ['SuburbId', 'Name'])\n",
    "    suburbs.columns = ['AdjacentSuburbId', 'SuburbId', 'Name']\n",
    "    suburbs = suburbs.drop('Name', axis=1)\n",
    "    suburbs_list = pd.concat([suburbs_list, suburbs])\n",
    "\n",
    "# get rid of rows where suburb == adjacent suburb (the api lists the own suburb as an adjacent suburb)\n",
    "suburbs_list['check'] = suburbs_list['AdjacentSuburbId'] - suburbs_list['SuburbId']\n",
    "suburbs_list = suburbs_list[suburbs_list['check'] != 0]\n",
    "suburbs_list = suburbs_list.drop('check', axis=1)\n",
    "suburbs_list.columns = ['id_adjacent_suburb_tm', 'id_suburb_tm']\n",
    "suburbs_list = location_md.con_website.table_lookup(df=suburbs_list, df_lookup_column_list=['id_suburb_tm'],\n",
    "                                             table='analytics_suburb',\n",
    "                                             table_lookup_column_list=['id_suburb_tm'],\n",
    "                                             table_return_column_list=['id_suburb'], return_suffix='_tblid',\n",
    "                                             indicator=False)\n",
    "suburbs_list = location_md.con_website.table_lookup(df=suburbs_list, df_lookup_column_list=['id_adjacent_suburb_tm'],\n",
    "                                             table='analytics_suburb',\n",
    "                                             table_lookup_column_list=['id_suburb_tm'],\n",
    "                                             table_return_column_list=['id_suburb'], return_suffix='_adjtblid',\n",
    "                                             indicator=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_adjacent_suburb_tm</th>\n",
       "      <th>id_suburb_tm</th>\n",
       "      <th>id_suburb</th>\n",
       "      <th>id_suburb_adjtblid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id_adjacent_suburb_tm, id_suburb_tm, id_suburb, id_suburb_adjtblid]\n",
       "Index: []"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suburbs_list[pd.isnull(suburbs_list['id_suburb_adjtblid'])]#['id_adjacent_suburb_tm'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5099"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(suburbs_list.dropna(axis=0)) #['id_adjacent_suburb_tm'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "location_md.run_adjacent_suburbs()\n",
    "location_md.adjacent_suburbs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "location_md.update_adjacent_suburbs_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame([[1, 1, 1], [1, 1, 2], [2, 2, 2], [3, 3, 3]], columns=['id_region', 'id_district', 'id_suburb'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfm = pd.merge(df, df2, how='left', on=['id_region', 'id_district', 'id_suburb'], indicator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "add = dfm[dfm['ind']=='left_only']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "location_md.suburb_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "location_md.run_location()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "location_md.location_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# location_md.update_district_table()\n",
    "location_md.update_region_table()\n",
    "# location_md.update_suburb_table()\n",
    "# location_md.update_location_table()\n",
    "# location_md.update_adjacent_suburbs_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = pd.DataFrame([[1,2,3],[1,2,4]],columns=['one','two','three'])\n",
    "b = a.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.merge(a, b, on='one', indicator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "a['new']=datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a.rename(columns={'new': 'last_'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a.to_json(orient='records', date_format='iso')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user='housingdata'; passwd='housingdata123'; host='housing-postgres.ct0tluqftf3s.ap-southeast-2.rds.amazonaws.com'\n",
    "db='housingwebsite'\n",
    "engine = create_engine('postgresql+psycopg2://%s:%s@%s:5432/%s' % (\n",
    "            user, passwd, host, db))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "con = engine.connect()\n",
    "con.execute(\"set search_path to website\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "con.execute(\"set search_path to website\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_sql(\"SELECT * FROM analytics_region\", con=con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.drop(['id_region', 'last_updated'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "table = [[1, 'region', 13], [3, 'asd', 15]]\n",
    "dfin = pd.DataFrame(table, columns=['id_region', 'name', 'id_region_tm'])\n",
    "dfin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df.set_index('name', drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a=True\n",
    "b=False\n",
    "c=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test():\n",
    "    print('a')\n",
    "def test2():\n",
    "    print('b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tt = {'a':12, \n",
    "     'tests': [test, test2]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tt['tests'][1]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.rename(columns={'id_region':'regionid', 'last_updated':'dss_update'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not a and b and c:\n",
    "    print('exit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.merge(df, dfin, how='left', left_index=True, right_on='id_region', indicator=True, suffixes=('', '_tbl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = pd.DataFrame([[1, 2], [3, 4]], columns=['a', 'b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b = pd.DataFrame([[1, 2], [9, 9]], columns=['a', 'b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.merge(a, b, how='left', left_on=['a', 'b'], right_on=['a', 'b'], indicator=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* check listing_id for new rows\n",
    "* insert new rows\n",
    "* check active rows in website table not in staging, and remove them\n",
    "* check for changes to existing rows (no nede to take existing rows out cause they've been written already)\n",
    "* add in new rows (and change version_from and version_to to new values)\n",
    "* change in old listing_id rows version_from and version_to and version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r = a.region()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "engine = create_engine('postgresql+psycopg2://housingdata:housingdata123@housing-postgres.ct0tluqftf3s.ap-southeast-2.rds.amazonaws.com:5432/housingwebsite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    con = engine.connect()\n",
    "except exc.OperationalError:\n",
    "    print('failed')\n",
    "    raise exc.OperationalError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "con.execute(\"set search_path to website\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a =con.execute(\"DELETE FROM analytics_region\")  # autocommit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pgconn = psycopg2.connect(\"\"\"host='housing-postgres.ct0tluqftf3s.ap-southeast-2.rds.amazonaws.com'\n",
    "                            dbname='housingwebsite' user='housingdata'\n",
    "                          password='housingdata123'\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pgconn.execute('set search_path to website')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conn = pygrametl.ConnectionWrapper(connection=pgconn)\n",
    "conn.execute('set search_path to website')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dim = Dimension(\n",
    "    name='analytics_region',\n",
    "    key='id_region',\n",
    "    attributes=['name', 'last_updated'],\n",
    "    lookupatts=['name'],\n",
    "    targetconnection=conn\n",
    ")\n",
    "for rows in r:\n",
    "    try:\n",
    "        dim.insert(rows)\n",
    "    except:\n",
    "        conn.rollback()\n",
    "\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
