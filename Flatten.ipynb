{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import json\n",
    "from sqlalchemy import create_engine\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating connection to database housing with schema staging\n",
      "creating connection to database housing with schema housing\n",
      "creating connection to database housing with schema staging\n",
      "creating connection to database housing with schema housing\n",
      "UPDATE_RENTAL_LISTINGS\n",
      "['photo_main', 'end_date', 'start_date', 'is_classified', 'id_listing_tm', 'amenities', 'available_from', 'bathrooms', 'bedrooms', 'best_contact_time', 'ideal_tenant', 'listing_group', 'max_tenants', 'parking', 'pets_okay', 'price_display', 'property_id', 'property_type', 'smokers_okay', 'start_price', 'title', 'rent_per_week', 'whiteware', 'address', 'latitude', 'longitude', 'easting', 'northing', 'agency_reference', 'category', 'category_path', 'has_embedded_video', 'has_gallery', 'is_bold', 'is_featured', 'is_highlighted', 'is_super_featured', 'listing_length', 'reserve_state', 'is_boosted', 'id_agency_tm', 'id_suburb_tm', 'note_date']\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "import ETLTools\n",
    "from Email_Tools import EmailConnection\n",
    "\n",
    "\n",
    "class Listings(ETLTools.ETLTools):\n",
    "    \"\"\"\n",
    "    1a. Check Listing ID for new rows\n",
    "    1b. Populate ALL tables with new listing information\n",
    "    2a. Check active rows in website tables that aren't in staging\n",
    "    2b. Set is_current to False\n",
    "    3a. Check for changes to existing rows\n",
    "    3b. For existing rows that changed, change the is_current, valid_from, valid_to and version\n",
    "    3c. Add in the changed rows in ALL tables with new timestamps and versions\n",
    "    \"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Initialize Listings object\n",
    "        :param connect_staging: Boolean initialize object to connect to staging table\n",
    "        :param st_user: staging username\n",
    "        :param st_passwd: staging password\n",
    "        :param st_host: staging host\n",
    "        :param st_db: staging database\n",
    "        :param st_schema: staging schema\n",
    "        :param connect_website: Same as above, except connect to the website. Params are prefixed with 'ws'\n",
    "        \"\"\"\n",
    "        # connection object for staging\n",
    "        if kwargs.get('connect_staging', None):\n",
    "            self.con_staging = ETLTools.DatabaseConnection(\n",
    "                kwargs['st_user'], kwargs['st_passwd'], kwargs['st_host'], kwargs['st_db'], kwargs['st_schema'])\n",
    "        # connection object for website\n",
    "        if kwargs.get('connect_data', None):\n",
    "            self.con_data = ETLTools.DatabaseConnection(\n",
    "                kwargs['dt_user'], kwargs['dt_passwd'], kwargs['dt_host'], kwargs['dt_db'], kwargs['dt_schema'])\n",
    "\n",
    "        self.agency_flag = 0\n",
    "        self.rental_listings_flag = 0\n",
    "        self.agent_rental_flag = 0\n",
    "        self.rental_photo_flag = 0\n",
    "        self.agency_error = None\n",
    "        self.rental_listings_error = None\n",
    "        self.agent_rental_error = None\n",
    "        self.rental_photo_error = None\n",
    "\n",
    "    def run_all_etl(self):\n",
    "        opening = time.time()\n",
    "        tries = 0\n",
    "        #emc = EmailConnection(aws_id='AKIAJUKW4BKB6I2O3JOA', aws_secret='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')\n",
    "        while tries < 2:\n",
    "            print('initialising transaction')\n",
    "            self.con_data.create_transaction()\n",
    "            self.update_rental_listings()\n",
    "            self.update_agency()\n",
    "            self.update_agent_rental()\n",
    "            self.update_rental_photo()\n",
    "            #if (self.rental_listings_flag) == 1:\n",
    "            if (self.agency_flag + self.rental_listings_flag + self.agent_rental_flag + self.rental_photo_flag) == 4:\n",
    "                self.con_data.commit_transaction()\n",
    "                self.con_data.close_connection()\n",
    "                # emc.send_email(from_address='housedatawebsite@gmail.com',\n",
    "                #                to_address_list=['housedatawebsite@gmail.com'],\n",
    "                #                subject='Success! %s' % str(self.datenow()), body='')\n",
    "                print('total time: %s' % (time.time() - opening))\n",
    "                exit()\n",
    "            else:\n",
    "                self.con_data.rollback_transaction()\n",
    "                tries += 1\n",
    "        print('closing connection')\n",
    "        self.con_data.close_connection()\n",
    "        error_list = []\n",
    "        for e in enumerate([self.agent_rental_error, self.rental_listings_error,\n",
    "                            self.agency_error, self.rental_photo_error]):\n",
    "            if e:\n",
    "                error_list.append(e)\n",
    "        # emc.send_email(from_address='housedatawebsite@gmail.com', to_address_list=['housedatawebsite@gmail.com'],\n",
    "        #                subject='Error!', body='errors: \\n' + str(error_list))\n",
    "\n",
    "    \"\"\"Generic Functions\"\"\"\n",
    "    def _control(self, table):\n",
    "        \"\"\"\n",
    "        Returns a dataframe of the staging.control table\n",
    "        :param table: Table name in control table\n",
    "        :return: pandas DataFrame of staging.control\n",
    "        \"\"\"\n",
    "        return self.generator_to_df(self.con_staging.query(\n",
    "            \"SELECT source_col_name, dest_col_name, \\\"type\\\" FROM control WHERE dest_table_name = '%s'\" % table),\n",
    "            columns=['source_col_name', 'dest_col_name', 'type'])\n",
    "\n",
    "    def _control_mapping_columns(self, table):\n",
    "        \"\"\"\n",
    "        Returns source and destination mapping columns of table \n",
    "        :param table: relevant destination table\n",
    "        :return: DICTIONARY of source and destination mapping lists\n",
    "        \"\"\"\n",
    "        df = self._control(table)\n",
    "        source_mapping = list(df[df['type'] == 'mapping']['source_col_name'])\n",
    "        destination_mapping = list(df[df['type'] == 'mapping']['dest_col_name'])\n",
    "        return {'source_mapping': source_mapping, 'destination_mapping': destination_mapping}\n",
    "\n",
    "    def _control_source_columns(self, table, return_as_str=False):\n",
    "        \"\"\"\n",
    "        Finds the source columns for any given table\n",
    "        :param table: destination table\n",
    "        :param return_as_str: return as a string separated by \",\" commas\n",
    "        :return: LIST of columns in the source table\n",
    "        \"\"\"\n",
    "        if return_as_str:\n",
    "            return ', '.join(list(self._control(table).dropna()['source_col_name']))\n",
    "        return list(self._control(table).dropna()['source_col_name'])\n",
    "\n",
    "    def _control_destination_columns(self, table, key=True, meta=True, mapping=True):\n",
    "        \"\"\"\n",
    "        Finds the destination columns for any given table. Note this DOES NOT return metadata fields.\n",
    "        :param table: destination table\n",
    "        :param key: boolean to include the primary key of the destination table in output list\n",
    "        :param meta: boolean to include metadata columns\n",
    "        :param mapping: boolean to pull the mapping columns\n",
    "        :return: LIST of columns in the destination table\n",
    "        \"\"\"\n",
    "\n",
    "        df = self._control(table)\n",
    "        if not key:\n",
    "            df = df[df['type'] != 'pk']\n",
    "        if not meta:\n",
    "            df = df[df['type'] != 'metadata']\n",
    "        if not mapping:\n",
    "            df = df[df['type'] != 'mapping']\n",
    "        return list(df['dest_col_name'])\n",
    "\n",
    "    def _control_date_cols(self, table, kind='dest_col_name'):\n",
    "        date_ctrl = self._control(table)\n",
    "        return list(date_ctrl[date_ctrl['type'] == 'datetime'][kind])\n",
    "\n",
    "    def convert_ms_dates(self, df, table):\n",
    "        date_cols = self._control_date_cols(table)\n",
    "        for cols in date_cols:\n",
    "            df[cols] = df[cols].apply(lambda x: self.from_ms_timestamp(int(x[x.find(\"(\")+1:x.find(\")\")])))\n",
    "        return df\n",
    "\n",
    "    def convert_dtype_dates(self, df, table):\n",
    "        date_cols = self._control_date_cols(table)\n",
    "        for cols in date_cols:\n",
    "            df[cols] = df[cols].astype('datetime64[ns, UTC]')\n",
    "        return df\n",
    "\n",
    "    def rental_listings(self, table='rental_listings'):\n",
    "        \"\"\"Completes jobs for rental_listings\"\"\"\n",
    "        \"\"\"Issues\n",
    "            Update Existing records is not joining properly to the table\n",
    "        \"\"\"\n",
    "        # try:\n",
    "\n",
    "        print('UPDATE_RENTAL_LISTINGS')\n",
    "\n",
    "        source_cols = self._control_source_columns(table=table)\n",
    "        destination_cols = self._control_destination_columns(table, key=False, meta=False,\n",
    "                                                             mapping=True)\n",
    "        print(destination_cols)\n",
    "        date_cols = self._control_date_cols(table)\n",
    "\n",
    "        staging_listings_df = self.generator_to_df(self.con_staging.query('SELECT %s FROM tm_rental_listings_hourly'\n",
    "                                                   % ', '.join(source_cols)), columns=destination_cols)\n",
    "        staging_listings_df = staging_listings_df.assign(is_current=1, valid_from=self.datenow(),\n",
    "                                                         valid_to=self.dateend(), row_insert_date=self.datenow())\n",
    "        staging_listings_df = self.convert_ms_dates(staging_listings_df, table)\n",
    "        staging_listings_df['start_date'] = staging_listings_df['start_date'].apply(lambda x: np.datetime64(x))\n",
    "        staging_listings_df['end_date'] = staging_listings_df['end_date'].apply(lambda x: np.datetime64(x))\n",
    "        return staging_listings_df\n",
    "        \n",
    "    def update_rental_listings(self, table='rental_listings'):\n",
    "        \"\"\"Completes jobs for rental_listings\"\"\"\n",
    "        \"\"\"Issues\n",
    "            Update Existing records is not joining properly to the table\n",
    "        \"\"\"\n",
    "        # try:\n",
    "\n",
    "        print('UPDATE_RENTAL_LISTINGS')\n",
    "\n",
    "        source_cols = self._control_source_columns(table=table)\n",
    "        destination_cols = self._control_destination_columns(table, key=False, meta=False,\n",
    "                                                             mapping=True)\n",
    "        print(destination_cols)\n",
    "        date_cols = self._control_date_cols(table)\n",
    "\n",
    "        staging_listings_df = self.generator_to_df(self.con_staging.query('SELECT %s FROM tm_rental_listings_hourly'\n",
    "                                                   % ', '.join(source_cols)), columns=destination_cols)\n",
    "        staging_listings_df = staging_listings_df.assign(is_current=1, valid_from=self.datenow(),\n",
    "                                                         valid_to=self.dateend(), row_insert_date=self.datenow())\n",
    "        staging_listings_df = self.convert_ms_dates(staging_listings_df, table)\n",
    "\n",
    "        # 1) Add new records\n",
    "        self.con_data.add_new_records(df=staging_listings_df, df_lookup_column_list=['id_listing_tm'],\n",
    "                                      table=table, table_lookup_column_list=['id_listing_tm'])\n",
    "\n",
    "        staging_listings_df['start_date'] = staging_listings_df['start_date'].astype('datetime64[ns, UTC]')\n",
    "        staging_listings_df['end_date'] = staging_listings_df['end_date'].astype('datetime64[ns, UTC]')\n",
    "\n",
    "        # 2) deactivate rows that aren't active anymore (ie. in datalayer but not staging)\n",
    "        # this is changing everything to old\n",
    "        print('***deactivating_old_listings***')\n",
    "        old_record_list = self.con_data.find_old_records(df=staging_listings_df,\n",
    "                                                         df_lookup_column_list=['id_listing_tm'],\n",
    "                                                         table=table,\n",
    "                                                         table_lookup_column_list=['id_listing_tm'],\n",
    "                                                         table_pk='id_rental_listing',\n",
    "                                                         convert_datetime_cols=date_cols)\n",
    "\n",
    "        if len(old_record_list) != 0:\n",
    "            print('deactivating %d records' %len(old_record_list))\n",
    "            self.con_data.query(\"UPDATE rental_listings SET is_current=0, valid_to='%s' WHERE id_rental_listing IN(%s)\"\n",
    "                                % (self.dateend(), ', '.join(old_record_list)))\n",
    "\n",
    "        # 3) update existing records\n",
    "        print('***update existing records***')\n",
    "        update_df = self.con_data.table_lookup(df=staging_listings_df,\n",
    "                                               df_lookup_column_list=destination_cols,  # destination_cols,\n",
    "                                               table=table,\n",
    "                                               table_lookup_column_list=destination_cols,  # destination_cols,\n",
    "                                               table_return_column_list=[],\n",
    "                                               wheresql=\"WHERE is_current = 1\",\n",
    "                                               convert_datetime_cols=date_cols)\n",
    "\n",
    "        print(destination_cols)\n",
    "\n",
    "        update_df = update_df[update_df['_merge'] == 'left_only']\n",
    "\n",
    "        if not len(update_df) == 0:\n",
    "            # update old rows\n",
    "            for ind, row in update_df.iterrows():\n",
    "                self.con_data.query(\"\"\"UPDATE %s\n",
    "                                       SET is_current = 0, valid_to = '%s' \n",
    "                                       WHERE id_listing_tm = '%s'\n",
    "                                       AND is_current = 1\n",
    "                                       \"\"\" % (table, self.datenow(), row['id_listing_tm']))\n",
    "            # write new rows. What is this doing?\n",
    "            update_df = update_df[staging_listings_df.columns]\n",
    "\n",
    "            self.con_data.append_df_to_table(df=update_df, table=table)\n",
    "\n",
    "        self.rental_listings_flag = 1\n",
    "        # except Exception as e:\n",
    "        #     self.rental_listings_error = e\n",
    "\n",
    "    \"\"\"Table Update Functions\"\"\"\n",
    "    def update_agency(self, table='agency'):\n",
    "\n",
    "        print('\\nUPDATE_AGENCY')\n",
    "        \"\"\"Updates the agency table\"\"\"\n",
    "        try:\n",
    "            source_agency_cols = self._control_source_columns(table, return_as_str=True)\n",
    "            destination_agency_cols = self._control_destination_columns(table, key=False, meta=False, mapping=True)\n",
    "            dest_map = self._control_mapping_columns(table=table)['destination_mapping']\n",
    "            agency_df = self.generator_to_df(self.con_staging.query(\"SELECT %s FROM tm_rental_listings_hourly\"\n",
    "                                                                    % source_agency_cols), columns=destination_agency_cols)\n",
    "            agency_df = agency_df.dropna(subset=['id_agency_tm'])\n",
    "            agency_df = agency_df.drop_duplicates(subset=['id_agency_tm'])\n",
    "            agency_df = agency_df.assign(row_insert_date=self.datenow())\n",
    "\n",
    "            agency_df = self.convert_ms_dates(agency_df, table)\n",
    "            type1 = [x for x in destination_agency_cols if x != 'id_agency_tm']\n",
    "            self.con_data.update_scd_type_one(df=agency_df, dimension_table=table, key='id_agency',\n",
    "                                              attributeslist=destination_agency_cols + ['row_insert_date'],\n",
    "                                              lookupatts=dest_map,\n",
    "                                              type1atts=type1 + ['row_insert_date']\n",
    "                                              )\n",
    "            self.agency_flag = 1\n",
    "        except Exception as e:\n",
    "            self.agency_error = e\n",
    "\n",
    "    def update_agent_rental(self, table='rental_agent'):\n",
    "\n",
    "        print('\\nUPDATE_RENTAL_AGENT')\n",
    "\n",
    "        \"\"\"Updates the agent_rental table\"\"\"\n",
    "        # need to change the update strategy here. It doesn't add rows with 2 agents\n",
    "        try:\n",
    "            agent_source_cols = ['\"ListingId\"', '\"Agency_Agents_0_FullName\"',\n",
    "                                 '\"Agency_Agents_0_MobilePhoneNumber\"', '\"Agency_Agents_0_OfficePhoneNumber\"',\n",
    "                                 '\"Agency_Agents_0_Photo\"', '\"Agency_Agents_0_UrlSlug\"']\n",
    "            destination_cols = ['id_rental_listing', 'fullname', 'mobile', 'office_phone', 'photo', 'url_slug']\n",
    "            mapping_cols = self._control_mapping_columns(table)\n",
    "            agent_rental_df = pd.DataFrame(columns=destination_cols)\n",
    "            for i in range(2):\n",
    "                pull_cols = [x.replace('0', str(i)) for x in agent_source_cols]\n",
    "                df = self.generator_to_df(self.con_staging.query('SELECT %s FROM tm_rental_listings_hourly' % ', '\n",
    "                                                                 .join(pull_cols)), columns=destination_cols)\n",
    "                df = df[df['fullname'] != 'None']\n",
    "                df = df.dropna(subset=['fullname'])\n",
    "                agent_rental_df = pd.concat([agent_rental_df, df])\n",
    "\n",
    "            agent_rental_df = agent_rental_df.assign(row_insert_date=self.datenow())\n",
    "            agent_rental_df = self.convert_ms_dates(agent_rental_df, table)\n",
    "\n",
    "            # 1. Add new records\n",
    "            # delete from table where the keys join\n",
    "\n",
    "            rental_df = self.con_data.table_lookup(agent_rental_df, mapping_cols['destination_mapping'],\n",
    "                                                   table, mapping_cols['destination_mapping'])\n",
    "            rental_id_list = rental_df[rental_df['_merge'] == 'both'][mapping_cols['destination_mapping']]\n",
    "            self.con_data.query(\"DELETE FROM rental_agent WHERE id_rental_listing IN (%s)\"\n",
    "                                % ','.join(rental_id_list))\n",
    "            self.con_data.add_new_records(agent_rental_df, mapping_cols['destination_mapping'], table,\n",
    "                                          mapping_cols['destination_mapping'], None)\n",
    "            self.agent_rental_flag = 1\n",
    "\n",
    "        except Exception as e:\n",
    "            self.agent_rental_error = e\n",
    "\n",
    "    def update_rental_photo(self, table='rental_photo'):\n",
    "\n",
    "        print('UPDATE RENTAL PHOTO')\n",
    "        \"\"\"Updates the rental_photos table\"\"\"\n",
    "        # get source cols as list, and compare with long table of photo keyshe wont\n",
    "        try:\n",
    "            source_cols = self._control_source_columns(table)\n",
    "            mapping_cols = self._control_mapping_columns(table)\n",
    "            photo_cols = [x for x in source_cols if x not in ['\"ListingId\"', '\"PictureHref\"']]\n",
    "            photo_df = self.generator_to_df(\n",
    "                self.con_staging.query(\"SELECT %s FROM tm_rental_listings_hourly\" % ', '.join(source_cols)),\n",
    "                columns=source_cols)\n",
    "\n",
    "            photo_df = pd.melt(photo_df, id_vars=mapping_cols['source_mapping'], value_vars=photo_cols,\n",
    "                               var_name='photo_cols', value_name='photo_url')\n",
    "            photo_df = photo_df.rename(columns={'\"ListingId\"': 'id_rental_listing'})\n",
    "            photo_df = photo_df.drop('photo_cols', axis=1)\n",
    "            photo_df = photo_df.dropna(subset=['photo_url'])\n",
    "            photo_df = photo_df.assign(row_insert_date=self.datenow())\n",
    "            photo_df = self.convert_ms_dates(photo_df, table)\n",
    "\n",
    "            self.con_data.add_new_records(photo_df, df_lookup_column_list=['id_rental_listing', 'photo_url'],\n",
    "                                          table=table, table_lookup_column_list=['id_rental_listing', 'photo_url'])\n",
    "            self.rental_photo_flag = 1\n",
    "\n",
    "        except Exception as e:\n",
    "            self.rental_photo_error = e\n",
    "\n",
    "\n",
    "def run_listings():\n",
    "    ec2path = '/home/ubuntu/projects/housing/HousingETL/connections.json'\n",
    "    localpath = 'connections.json'\n",
    "    with open(localpath) as file:\n",
    "        web_con = json.load(file)\n",
    "    letl = Listings(connect_data=True, dt_user=web_con['dt_user'], dt_passwd=web_con['dt_passwd'],\n",
    "                    dt_host=web_con['dt_host'], dt_db=web_con['dt_db'], dt_schema=web_con['dt_schema'],\n",
    "                    connect_staging=True, st_user=web_con['st_user'], st_passwd=web_con['st_passwd'],\n",
    "                    st_host=web_con['st_host'], st_db=web_con['st_db'], st_schema=web_con['st_schema'])\n",
    "\n",
    "run_listings()\n",
    "\n",
    "with open('connections.json') as file:\n",
    "    web_con = json.load(file)\n",
    "letl = Listings(connect_data=True, dt_user=web_con['dt_user'], dt_passwd=web_con['dt_passwd'],\n",
    "                dt_host=web_con['dt_host'], dt_db=web_con['dt_db'], dt_schema=web_con['dt_schema'],\n",
    "                connect_staging=True, st_user=web_con['st_user'], st_passwd=web_con['st_passwd'],\n",
    "                st_host=web_con['st_host'], st_db=web_con['st_db'], st_schema=web_con['st_schema'])\n",
    "\n",
    "rl = letl.rental_listings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user='housingdata'; passwd='housingdata123'; host='housing.ct0tluqftf3s.ap-southeast-2.rds.amazonaws.com'\n",
    "db='housing'\n",
    "engine = create_engine('postgresql+psycopg2://%s:%s@%s:5432/%s' % (\n",
    "            user, passwd, host, db))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_sql(\"SELECT * FROM control WHERE dest_table_name='rental_listings'\", con=con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "con = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.result.ResultProxy at 0x1d86a8e7208>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.execute('set search_path to staging')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "join_cols = ['photo_main', \t'end_date', \t'start_date', \t'note_date', \t'is_classified', \t'id_listing_tm', \t'amenities', \t'available_from', \t'bathrooms', \t'bedrooms', \t'best_contact_time', \t'ideal_tenant', \t'listing_group', \t'max_tenants', \t'parking', \t'pets_okay', \t'price_display', \t'property_id', \t'property_type', \t'smokers_okay', \t'start_price', \t'title', \t'rent_per_week', \t'whiteware', \t'address', \t'latitude', \t'longitude', \t'easting', \t'northing', \t'agency_reference', \t'category', \t'category_path', \t'has_embedded_video', \t'has_gallery', \t'is_bold', \t'is_featured', \t'is_highlighted', \t'is_super_featured', \t'listing_length', \t'reserve_state', \t'is_boosted', \t'id_agency_tm', \t'id_suburb_tm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tbl = pd.read_sql(\"SELECT %s FROM housing.rental_listings WHERE is_current = 1\" % (','.join(join_cols)), con=con)\n",
    "len(df_tbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "housing = df_tbl.copy()\n",
    "staging = rl.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime64[ns, UTC]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "staging['end_date'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime64[ns, UTC]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing['end_date'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for col in join_cols:\n",
    "    df = pd.merge(left=staging, right=housing, how='left', on=col, suffixes=('', '_right'), indicator=True)\n",
    "    if len(df[df['_merge']=='left_only']) > 0:\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "staging.start_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "housing['end_date'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "staging['end_date'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for col in housing.columns:\n",
    "    print(col,': ', housing[col].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "housing['latitude'] = housing['latitude'].astype('float64')\n",
    "housing['longitude'] = housing['longitude'].astype('float64')\n",
    "housing['easting'] = housing['easting'].astype('float64')\n",
    "housing['northing'] = housing['northing'].astype('float64')\n",
    "staging['start_date'] = staging['start_date'].astype('datetime64[ns, UTC]')\n",
    "staging['end_date'] = staging['end_date'].astype('datetime64[ns, UTC]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for date in ('end_date', 'start_date', 'note_date'):\n",
    "    df[date] = df[date].astype('datetime64[ns]')\n",
    "    df_tbl[date] = df_tbl[date].astype('datetime64[ns]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfm = pd.merge(left=df, right=df_tbl, how='left', left_on=join_cols, right_on=join_cols, suffixes=('', '_tbl'), indicator=True)\n",
    "print(dfm['_merge'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['end_date'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['end_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['rent_per_week'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfm[dfm['_merge']==['left_only']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query = con.execute('Select \"ListingId\", \"PhotoUrls_0\", \t\"PhotoUrls_1\", \t\"PhotoUrls_10\", \t\"PhotoUrls_11\", \t\"PhotoUrls_12\", \t\"PhotoUrls_13\", \t\"PhotoUrls_14\", \t\"PhotoUrls_15\", \t\"PhotoUrls_16\", \t\"PhotoUrls_17\", \t\"PhotoUrls_18\", \t\"PhotoUrls_2\", \t\"PhotoUrls_3\", \t\"PhotoUrls_4\", \t\"PhotoUrls_5\", \t\"PhotoUrls_6\", \t\"PhotoUrls_7\", \t\"PhotoUrls_8\", \t\"PhotoUrls_9\", \t\"PictureHref\" FROM staging.tm_rental_listings_hourly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
